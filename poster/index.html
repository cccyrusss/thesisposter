<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
		<meta name="description" content="">
		<meta name="author" content="">
		<link rel="icon" href="../assets/conncomm_logo_2.ico">
		
		<title>Style transfer on human voiced music</title>
		
		<!-- Bootstrap core CSS -->
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
		
		<!-- fonts -->
		<link href="https://fonts.googleapis.com/css?family=Muli|Nunito|Poiret+One" rel="stylesheet">
		
		<!-- Custom styles for this template -->
		<link href="../css/thesisdemos.css" rel="stylesheet">
	</head>

	<body>
		<!-- main poster section -->
		<main role="main" class="container">
			
			<div class="row">
				<div class="col-lg-12">
					<h1 class="mt-4">Style transfer on human voiced music</h1>
					<h5 id="studentname">Cyrus Chun Ting Chu 44570552</h5>
				</div>
			</div>
			
			<div class="row mt-5">
				<div class="col-lg-6 col-sm-12">
					<h3>Generaive Adversarial Network (GAN)</h3>
					<ul>
						<li> Consists of two models, a discriminator and a generator </li>
						<li> Generator produces fake data, and discriminator distinguishes if the data is fake</li>
						<li> Theoratically, both can be trained until convergence, i.e., the discriminator can't distinguish if the data is fake</li>
					</ul>
				</div>
				<div class="col-lg-6 col-sm-12 text-center">
					<img src="https://developers.google.com/machine-learning/gan/images/gan_diagram.svg">
					<p> Basic GAN architecture (Source: <a href="https://developers.google.com/machine-learning/gan/gan_structure">Google</a>) </p>
				</div>
			</div>

			<div class="row mt-5">
				<div class="col-lg-6 col-sm-12">
					<h3>Motivation</h3>
					<ul>
						<li> Existing music generation techniques </li>
						<li> Image to Image Style Transfer </li>
						<li> Voice Conversion </li>
						<li> Audio Style Transfer </li>
					</ul>
				</div>
				<div class="col-lg-6 col-sm-12">
					<h3> Symbolic Music Style Transfer</h3>
					<ul>
						<li> Groove2Groove, uses an encoder-decoder neural network, including CNN and RNN</li>
						<li> Using CycleGAN, which was originally proposed for image style transfer </li>
					</ul>
				</div>
			</div>

			<div class="row mt-5">
				<div class="col-lg-12">
					<h3> My approach: MelGAN-VC </h3>
					<ul>
						<li> Has proven success on voice conversion and audio style transfer (arbitrarily long) </li>
						<li> Makes use of spectrograms, i.e., converts the input to spectrogram, transform it and convert it back to audio </li>
						<li> Uses TraVeL GAN instead of CycleGAN to avoid pixel-wise losses </li>
					</ul>
				</div>
			</div>
			
			<!-- this bit is for your video embed -->
			<hr>
			<div class="row mt-5 mb-5">
				<div class="col-lg-6 col-sm-12">
					<h3> Result </h3>
					<div class="embed-responsive embed-responsive-16by9">
						<!-- insert the embed code from youtube below here -->
						<iframe class="embed-responsive-item" src="https://www.youtube.com/embed/5qF_qbaWt3Q" allowfullscreen></iframe>
					</div>
				</div>
				<div class="col-lg-6 col-sm-12 text-center">
					<img src="../assets/losses.png" alt="Generator, discriminator(fake), Identity losses">
					<p> Average number of epochs per day: 25</p>
				</div>
			</div>
			<div class="row mt-5">
				<div class="col-lg-12">
					<h3> Evaluation </h3>
					<ul>
						<li> Needs a lot more epochs</li>
						<li> All the losses decreased during training, maybe a sign of success </li>
						<li> Talk about audio results (add later) </li>
					</ul>
				</div>
			</div>
			<hr>
			
			<!-- <div class="row mt-5">
				<div class="col-lg-8 col-sm-12">
					<h3>Arranged slightly differently</h3>
					<p>This bit is arranged a little differently with a wider column and then a narrower column to the left so you can add photos or images.  Again, it's up to you.  <span class="text-danger">Make sure that you check the criteria and the extra info sheet prepared by Pete and Jacki to make sure you are covering everything off.</span></p>
					<p>You add more sections below.</p>
				</div>
				<div class="col-lg-4 col-sm-12">
					<img src="../assets/cafe1.jpg" class="img-fluid mb-2" alt="describe any images in the alt text">
					<img src="../assets/street1.jpg" class="img-fluid mb-2" alt="describe any images in the alt text">
				</div>
			</div> -->
			
		</main><!-- /.container -->
		
		<!--/ biography modal -->
		<!-- <div class="modal fade" id="biographymodal" data-backdrop="static" data-keyboard="false" tabindex="-1" role="dialog" aria-labelledby="staticBackdropLabel" aria-hidden="true">
			<div class="modal-dialog">
				<div class="modal-content">
					<div class="modal-body">
						<div class="card">
							<img src="../assets/card_image.jpg" class="card-img-top" alt="Photo of the student">
							<h5 class="card-title mt-3">Cyrus Chu</h5>
							<p class="card-text">Final year Software Engineer Student</p>
						</div>
						<button type="button" class="close" data-dismiss="modal" aria-label="Close">
							<span aria-hidden="true">&times;</span>
						</button>
					</div>
				</div>
			</div>
		</div> -->
	
	
		<!-- Bootstrap core JavaScript -->
		<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
		<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
		
		<!-- Additional javascript -->
		<script src="../js/poster.js" type="text/javascript"></script>
	</body>
</html>
